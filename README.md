# File-preparation-for-Preservica 
# These scripts were originally created for University of the Arts London Archives and Special Collections Centre, for ingesting assets to our digital preservation system, Preservica, and also for enabling front-end display on our custom-built Digital Collections platform https://digitalcollections.arts.ac.uk/ . At UAL, metadata for different special collection objects is held in different legacy database systems, with different Reference Numbering conventions (based on different professional descriptive standards) depending on whether it had been catalogued as an archive, museum or library item. [Descriptive standards respectively: ISAD-G, SPECTRUM, MARC, and systems respectively: Axiell CALM; TMS (The Museum System); Koha]. 
# Preservica is an industry standard commercial software for Digital Preservation, based on the Open Source project https://www.accesstomemory.org/en/ it has an inbuilt way of syncing with records from the archive system Axiell CALM (soon to be obsolete in favour of Axiell Collections), but metadata in other systems needs to be packaged up in something called an .opex file in order to sync with the relevant legacy system.
# In order to structure the "Submission Information Packages" for Preservica to read and work with, assets needed packaging in an appropriate folder structure called a .pax  https://developers.preservica.com/documentation/preservation-asset-exchange-pax
# In this case, the .pax folders were to was to facilitate the preservation of scanned representations of the objects in hi-res .tif format, for Preservation, and medium-res .jpeg format, for Access. Many of the objects were also multi-part - so each part of the object digitised would have its own jpeg and tiff, and need to be grouped together in a meaningful way to associate them all with one object (reference number and its specific descriptive meta-data).
# The current project was working with archive (ISAD-G;CALM) and museum items (SPECTRUM;TMS) only. So there are two scripts here, one for structuring multi-reprepresentation, multi-part assets relating to digitised archival items; and one for   multi-reprepresentation, multi-part assets relating to digitised museum objects.
# Records from our Museum System, TMS, that cannot be automatically linked to their metadata in Preservica and therefore require a .opex file to be added. This is done in a separate bit of script at present - see the file [INCLUDE OPEX SCRIPT]

## For the Museum Object script: It selects jpegs as the "Access Representation" and tiffs as the "Preservation Representation" of a single asset (from a single, or multiple source folders, as defined), where the file names (minus the extension) match, assuming they have already been grouped together into folders per object, with a top-level folder giving the Museum Object reference number. [... note to self...explain this better!]. 
   ## The "regex" (regular expression) handle the particular naming structure of the file names in this instance, which were based on the Museum Object Reference Numbers
  ## After creating the .pax folder structure, it then also includes an extra folder "wrapper" for each .pax folder, to facilitate linking the metadata to each object at a level that can also be interpreted by our public front-end platform, Digital Collections, to show each object part within one object together. (This would not be necessary for items just being ingested in Preservica, and may just be to do with our particular set-up at UAL)

### For the Archive Object Script: This did not require a separate .opex file to be added, as with the correct settings in Preservica, and the reference numbers for the assets being correctly structured, it can automatically sync with the associated records in Axiell CALM
  ### However - the script does also include the same "wrapper" folder, enclosing each .pax, to facilitate the display of items on out Digital Collections platform. (Again, this would not be necessary for items just being ingested in Preservica, and may just be to do with our particular set-up at UAL)
  
# I wrote thes in dialogue with Chat CPT who also helped me to create a "dry run" mode and a "roll back" mode, to check it was working properly before moving the files into the relevant folder structure.
# All open to use by interested archivists and or coders working with archives, but grateful if you can credit me - Lucy Catherine Parker https://www.linkedin.com/in/lucycatherineparker/  ... and Chat GPT ;) Thanks to colleagues Elisabeth Thurlow for support managing me in this project and Erin Liu for ongoing dialogue (including her critical take on the use of AI for coding! Warning to others - do test things out properly and use AI with due diligence, testing, etc.)
